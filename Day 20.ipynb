{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_input = \"day20_my_input.txt\"\n",
    "test_input = \"day20_test_input.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "class ParticleSwarm:\n",
    "    def __init__(self, data_file):\n",
    "        self._positions = list()\n",
    "        self._velocities = list()\n",
    "        self._accelerations = list()\n",
    "        self._load_data(data_file)\n",
    "#         print(self._positions)\n",
    "#         self._simulate_movement()\n",
    "    \n",
    "    def closest_to_zero(self):\n",
    "        dtype = [('particle_id', int), ('acceleration', int), ('velocity', int), ('position', int)]\n",
    "        \n",
    "        values = list()\n",
    "        \n",
    "        manhattan_accelerations = np.sum(np.absolute(self._accelerations), axis=1)\n",
    "        manhattan_velocities = np.sum(np.absolute(self._velocities), axis=1)\n",
    "        manhattan_positions = np.sum(np.absolute(self._positions), axis=1)\n",
    "        \n",
    "        for particle_id, _ in enumerate(manhattan_positions):\n",
    "            value = (particle_id, manhattan_accelerations[particle_id],\n",
    "                    manhattan_velocities[particle_id], manhattan_positions[particle_id])\n",
    "            values.append(value)\n",
    "            \n",
    "        particles = np.array(values, dtype=dtype)\n",
    "        \n",
    "        closest_to_zero = np.sort(particles, order=['acceleration', 'velocity', 'position'])[0]\n",
    "        \n",
    "        return closest_to_zero['particle_id']\n",
    "        \n",
    "        \n",
    "    def _simulate_movement(self, ticks=10000000):\n",
    "        for tick in range(ticks):\n",
    "            self._velocities += self._accelerations\n",
    "            self._positions += self._velocities\n",
    "        \n",
    "        distances = np.sum(np.absolute(self._positions), axis=1)\n",
    "        print(np.argmin(distances))\n",
    "        \n",
    "    def _load_data(self, data_file):\n",
    "        with open(data_file) as f:\n",
    "            for line in f:\n",
    "                position = self._get_particle_details('p', line)\n",
    "                self._positions.append(position)\n",
    "                velocity = self._get_particle_details('v', line)\n",
    "                self._velocities.append(velocity)\n",
    "                acceleration = self._get_particle_details('a', line)\n",
    "                self._accelerations.append(acceleration)\n",
    "        \n",
    "        self._positions = np.array(self._positions)\n",
    "        self._velocities = np.array(self._velocities)\n",
    "        self._accelerations = np.array(self._accelerations)\n",
    "                \n",
    "    def _get_particle_details(self, symbol, string):\n",
    "        details = re.search(f'{symbol}=<(.+?)>', string).groups()[0].split(',')\n",
    "        return list(map(int, details))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ParticleSwarm(my_input).closest_to_zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "input = open(my_input).read().splitlines()\n",
    "\n",
    "position = dict()\n",
    "velocity = dict()\n",
    "acceleration = dict()\n",
    "\n",
    "from numpy import *\n",
    "\n",
    "for index, line in enumerate(input):\n",
    "    tokens = line.split()\n",
    "    pos = tokens[0][3:-2].split(',')\n",
    "    vel = tokens[1][3:-2].split(',')\n",
    "    acc = tokens[2][3:-1].split(',')\n",
    "    position[index] = array([int(pos[0]), int(pos[1]), int(pos[2])])\n",
    "    velocity[index] = array([int(vel[0]), int(vel[1]), int(vel[2])])\n",
    "    acceleration[index] = array([int(acc[0]), int(acc[1]), int(acc[2])])\n",
    "\n",
    "def tick():\n",
    "    for index in acceleration.keys():\n",
    "        velocity[index] += acceleration[index]\n",
    "        position[index] += velocity[index]\n",
    "    collide()\n",
    "\n",
    "from collections import defaultdict\n",
    "def collide():\n",
    "    collision = defaultdict(set)\n",
    "    for index, p in position.items():\n",
    "        t = p[0], p[1], p[2]\n",
    "        collision[t].add(index)\n",
    "    for pos, items in collision.items():\n",
    "        if len(items) > 1:\n",
    "            for item in items:\n",
    "                del position[item]\n",
    "                del velocity[item]\n",
    "                del acceleration[item]\n",
    "\n",
    "for i in range(20000):\n",
    "    tick()\n",
    "print(len(position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
